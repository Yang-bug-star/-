关键词：graph matching、cross-domain alignment、distribution match

《JointGT_Graph-Text Joint Representation Learning for Text Generation》#使用了 cross-domain alignment technique: Optimal Transport（fine-grained——word vs entity，minimizing the cost of transporting one distribution to another）

embedding distribution（a set of embeddings，)

alignment学习有隐式（induce）和显式的

《GOPT(2020)》:在主损失函数上加上一项对齐regularization项to regularize，设计$L_{CDA}$

$\downarrow$

Li et al. (2019b) ——graph matching network (GMN)——soft attention to induce alignment

https://github.com/ LiqunChen0606/Graph-Optimal-Transport

And Optimal transport for structured data with application on graphs(Vayer,2018)——fused GWD



##### distance-based

probability distribution distance metric for matching: $\begin{cases}Wasserstein:&&node\ feature\ across\ graph\\Gromov-Wasserstein:&&structure\ across\  graph\\fused\ Gromov-Wasserstein:&&\end{cases}$

要match借助某种相似性度量，最大化该相似性 

《JointGT_Graph-Text Joint Representation Learning for Text Generation》2021 -> 《UNITER: UNiversal Image-TExt Representation Learning》2020 -> 《Stacked Cross Attention for Image-Text Matching》2018(有监督的：需要构建positive pair和negative pair

over all negatives

![image-20221104084522970](C:\Users\91889\AppData\Roaming\Typora\typora-user-images\image-20221104084522970.png)

focus on hardest pair

![image-20221104084732314](C:\Users\91889\AppData\Roaming\Typora\typora-user-images\image-20221104084732314.png)

《Improving Multimodal Named Entity Recognition via Entity Span》2020—cross attention模块就是query交互，还是有监督的，要求paired image和text，需要样本对，这种cross attention只能实现隐式对齐，修改transformer架构hword representation不是简单地使用静态的word2vec，而是考虑context动态生成向量表示的bert，同一个词依据所处环境不同而具有不同的表示

《Improving Vector Space Word Representations Using Multilingual Correlation》2014（CCA，  canonical  correlation  analysis）——半监督，需要seed 样本对，只能得到线性关联，好朴素，就是原来的关联经线性映射后仍最大化保留，在seed样本对训练集上训练确定映射矩阵参数，然后再映射剩余未匹配的(相当于测试集)

-> 《 Inducing crosslingual distributed representations of words.》2012（multitask learning framework）

《Massively Multilingual Word Embeddings》——multiCCA 依然是有监督的，需要样本对（eg.entity vs word)，利用中间矩阵媒介转换到同一个样本空间，并带约束->原来样本对的相似性经映射后仍得到保持

《Multi-view Knowledge Graph Embedding for Entity Alignment》2019 缺少seed entity alignment怎么办,如何构造seed entity alignment->soft alignment——

-> 《Cross-lingual entity alignment via joint attribute-preserving embedding》2017 | 《Co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment》2018 | 《Entity alignment between knowledge graphs using attribute embeddings》2019|《Modeling relational data with graph convolutional networks》2017 | 《Cross-lingual knowledge graph alignment via graph convolutional networks》 2018b



11.5《Translating Embeddings for Modeling Multi-relational Data》 2013 —— 提出获取KB 中entity和relationship的embedding方法，注意entity embedding需要范数为1，关键的是entity和relation都训练得到embedding

![image-20221107144504679](C:\Users\91889\AppData\Roaming\Typora\typora-user-images\image-20221107144504679.png)



11.7《A semantic matching energy function for learning with multi-relational data》不是我想要的，还是提出类似于translate中d(h,t)的方式（只不过把d名为energy function，对的triplet的energy较低）对KB进行编码，并没有异构数据表示的对齐方式



11.7 《Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network》—— #cross-lingual KG之间的对齐。克服仅依赖单一图谱结构化信息对entity编码导致的对具不同fact的entity难以match的不足，引入topic entiy graph作为邻域信息，既有local node matching 也有global graph match，将entity alignment视作子图graph matching问题。要求-有监督，需要有已匹配的entity对作为正例以构造负例（tail不动，将head换成与原来head相近的前k个），针对有向图（考虑入度和出度），没有考虑关系的标签类型细节，忽略关系标签，仅考虑关系的方向。观察到entity的名字表面信息对于对齐非常有用，整个图级别的match可以使得局部node match信息在整个图中流动改善对于那些邻居很少或邻域信息差别较大的entity的匹配。



11.7 《Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network》



关键词-semantic gap between natural language expression and item-level user preference.

align the word-level and entity-level semantic space

semantic representation alignment

semantic gap between the two kinds of data signal

semantic fusion in CRS

semantic gap between natural language and external knowledge

word-level and entity-level semantic space

dialog component and the recommender component alignment

KG based semantic fusion

fuse semantic space

unify data representation in different semantic spaces

unify representation space

,
mutually improve the data representations of two coupled signals

align their semantic representation space